---
title: "CHILDES-Q Visualization"
author: "Kyle MacDonald"
output: html_document
---

## Set up

```{r, include = F}
knitr::opts_chunk$set(echo=T, warning=FALSE, message=FALSE,
                      fig.width=12, fig.height=8)
```

```{r}
rm(list=ls())
library(ggrepel)
library(magrittr)
library(stringr)
library(knitr)
library(tidyverse)
library(RMySQL)
library(directlabels)
library(tidytext)
library(forcats)
theme_set(ggthemes::theme_few())
```

## Read data

```{r}
all_qs <- read_csv("../../data/queries/childes_questions.csv")
```

Clean up child variable

```{r}
all_qs %<>% 
  mutate(child_clean = ifelse(str_detect(child, "ale"), "alex",
                              ifelse(str_detect(child, "eth"), "ethan",
                                     ifelse(str_detect(child, "lil"), "lily",
                                            ifelse(str_detect(child, "nai"), "naima", 
                                                   ifelse(str_detect(child, "vio"), "violet", 
                                                          ifelse(str_detect(child, "wil"), "william",
                                                                 ifelse(str_detect(child, "n"), "naomi_s",
                                                                        child))))))))
```

Only keep questions with known question words

```{r}
all_qs_filt <- all_qs %>% filter(question_word != "other", gloss != "show")
```

## Descriptives

```{r}
all_qs_filt %>% distinct(corpus) %>% kable()
```

How many children in dataset? 

```{r}
all_qs_filt %>% 
  distinct(child_clean) %>% 
  nrow() %>% 
  paste("n children =", .)
```

```{r}
all_qs_filt %>% 
  ungroup() %>% 
  group_by(speaker_clean, question_word, length_transcript) %>% 
  summarise(count = n()) %>%
  ggplot(., aes(x = question_word, y = count)) +
  geom_bar(stat = "identity") +
  labs(x = "Question Word") +
  facet_wrap(~speaker_clean)
```

```{r}
all_qs_filt %>% 
  group_by(speaker_clean) %>% 
  summarise(count = n())
```

```{r}
all_qs_filt %>% 
  filter(speaker_clean == "child") %>% 
  select(question_word, sentgloss, age_months) %>% 
  group_by(question_word) %>% 
  sample_n(., size = 1) %>% 
  knitr::kable()
```

## Exploratory analyses

Histogram of question types for each child

```{r}
all_qs_filt %>% 
  ungroup() %>% 
  filter(speaker_clean == "child") %>% 
  group_by(child_clean, question_word, length_transcript) %>% 
  summarise(freq = n()) %>% 
  ggplot(., aes(x = question_word, y = freq)) +
  geom_bar(stat = "identity") +
  labs(x = "Question Word", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~child_clean)
```

Count different kinds of questions for each kid and plot as a function of age.

```{r}
all_qs_filt %>% 
  filter(speaker == "CHI") %>% 
  group_by(child_clean, age_months, question_word, length_transcript) %>% 
  summarise(freq = n()) %>% 
  filter(freq > 0) %>% 
  mutate(prop = freq / length_transcript) %>%
  ggplot(., aes(x = age_months, y = prop, color = question_word)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "loess", se = F) +
  labs(color = "question word", y = "Prop. of Utterances") +
  langcog::scale_color_solarized() +
  facet_wrap(~child_clean, ncol = 7,  scales = "free_y") +
  theme(legend.position = "bottom") +
  ggtitle("Children's questions")
```

Count different kinds of questions for each adult and summarise over development

```{r}
all_qs_filt %>% 
  filter(speaker_clean != "child") %>% 
  group_by(child_clean, age_months, question_word, length_transcript) %>% 
  summarise(freq = n()) %>% 
  filter(freq > 0) %>% 
  mutate(prop = freq / length_transcript) %>% 
  ggplot(., aes(x = age_months, y = prop, color = question_word)) +
  geom_smooth(method = "loess", se = F) +
  labs(color = "question word", x = "Age (months)", y = "Prop. of Utterances") +
  langcog::scale_color_solarized() +
  facet_wrap(~child_clean, ncol = 7) +
  theme(legend.position = "bottom") +
  ggtitle("Adults' questions")
```

Now get the average frequency for each question type at each month of development.

```{r}
all_qs_filt %>% 
  filter(question_word %in% c('what', 'where', 'why', 'who', 'how', 'when')) %>% 
  group_by(child_clean, age_months, question_word, 
           speaker_clean, length_transcript) %>% 
  summarise(freq = n()) %>% 
  filter(freq > 0) %>% 
  mutate(prop = freq / length_transcript) %>% 
  group_by(child_clean, age_months, question_word, speaker_clean) %>% 
  summarise(m = mean(prop, na.rm = T)) %>% 
  group_by(age_months, question_word, speaker_clean) %>% 
  summarise(m = mean(m),
            n = n()) %>% 
  ggplot(., aes(x = age_months, y = m, color = question_word)) +
  geom_point(aes(size = n), alpha = 0.3) +
  geom_smooth(se=F, method = "loess", size = 2) +
  xlim(10, 68) +
  labs(y = "Prop. of Utterances", x= "Age (months)") +
  guides(color = F) +
  langcog::scale_color_solarized() +
  geom_dl(aes(label = question_word), method=list("last.points")) +
  facet_wrap(~speaker_clean, scales = "free") +
  theme(legend.position = "top")
```

### Gender analysis

```{r}
gender_ms <- all_qs_filt %>% 
  group_by(child_clean, question_word, speaker_clean, gender, length_transcript) %>% 
  summarise(freq = n()) %>%
  filter(freq > 0, gender %in% c("male", "female")) %>% 
  mutate(prop = freq / length_transcript) %>% 
  group_by(child_clean, question_word, speaker_clean, gender) %>% 
  summarise(mean_prop = mean(prop)) %>% 
  group_by(question_word, speaker_clean, gender) %>% 
  langcog::multi_boot_standard(column = "mean_prop", empirical_function = "mean") 
```

```{r}
gender_ms %>% 
  ggplot(., aes(x = question_word, y = mean, color = gender)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = 0.3), size = 0.8) +
  labs(y = "Avg. Freq", x= "Question Type") +
  langcog::scale_color_solarized() +
  facet_wrap(~speaker_clean, scales = "free") +
  theme(legend.position = "top")
```

### Context analyses

Here we will attempt to operationalize cost and reward of a behavior to get the value for a question.

Spread participants variable, so we can code for the number of people in the conversation.

```{r}

```

### Complexity of utterance that each question word occurs in

Use some string functions to get the word count for each utterance.

```{r}
all_qs_filt %<>% 
  rowwise() %>% 
  mutate(sentence_len = length(strsplit(sentgloss,' ')[[1]]))
```

Now summarise the mean sentence length for each question type for each kid and speaker

```{r}
sentence_len_ms <- all_qs_filt %>% 
  ungroup() %>% 
  group_by(age_months, speaker_clean, child_clean, question_word) %>% 
  summarise(m.ss = median(sentence_len), 
            n = n()) %>% 
  group_by(age_months, speaker_clean, question_word) %>% 
  summarise(m = mean(m.ss), 
            n = n()) 
```

```{r}
sentence_len_ms %>% 
  filter(question_word %in% c('what', 'where', 'why', 'who', 'how', 'when')) %>% 
  ggplot(data = ., aes(x = age_months, y = m, color = question_word)) +
  geom_point(aes(size = n), alpha = 0.3) +
  geom_smooth(se=F, method = "loess", size = 2) +
  xlim(10, 68) +
  labs(y = "Avg. Sentence Length", x = "Age (months)") +
  guides(color = F) +
  langcog::scale_color_solarized() +
  geom_dl(aes(label = question_word), method=list("last.points")) +
  facet_wrap(~speaker_clean) +
  theme(legend.position = "top")
```

### Single question word utterances

```{r}
single_words <- all_qs_filt %>% 
  filter(sentence_len == 1) %>% 
  group_by(speaker_clean, child_clean, question_word, 
           age_months, length_transcript) %>% 
  summarise(freq = n()) %>% 
  mutate(prop = freq / length_transcript) %>% 
  group_by(speaker_clean, child_clean, question_word, age_months) %>% 
  summarise(m = mean(prop)) %>% 
  group_by(speaker_clean, question_word, age_months) %>% 
  summarise(m.ss = median(m), 
            n = n())
```

```{r}
single_words %>% 
  #filter(question_word %in% c("where", "what", "why")) %>% 
  filter(question_word %in% c('what', 'where', 'why', 'who', 'how', 'when'), 
         age_months <= 60) %>%
  ggplot(data = ., aes(x = age_months, y = m.ss, color = question_word)) +
  geom_point(aes(size = n), alpha = 0.3) +
  geom_smooth(se=F, method = "loess", size = 2) +
  xlim(10, 68) +
  guides(color = F) +
  labs(y = "Prop. of Utterances", x = "Age (months)") +
  langcog::scale_color_solarized() +
  geom_dl(aes(label = question_word), method=list("last.points")) +
  facet_wrap(~speaker_clean) +
  theme(legend.position = "top")
```

## Word frequencies in question utterances

```{r}
unigrams_df <- all_qs %>% 
  distinct(sentgloss, .keep_all = T) %>% 
  unnest_tokens(word, sentgloss) %>% 
  select(-gloss)
```

Remove stop words

```{r}
custom_stop_words <- bind_rows(data_frame(word = cust_stop_vect, 
                                          lexicon = c("custom")))
```

```{r}
unigrams_df %<>% anti_join(custom_stop_words)
```

What are the most common words that occur in utterances flagged as questions?

```{r}
plot_qs <- unigrams_df %>% 
  group_by(word, question_word) %>% 
  count() %>%
  ungroup() %>% 
  top_n(30) %>% 
  arrange(desc(n)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))
```

```{r}
plot_qs %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = question_word)) +
  geom_col() +
  labs(x = NULL, y = "count") +
  coord_flip()
```

Plot for each question word

```{r}
unigrams_df %>%
  group_by(question_word, word) %>% 
  count() %>% 
  top_n(5) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = question_word)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "count") +
  facet_wrap(~question_word, scales = "free") +
  coord_flip()
```

Remove stop words and do the same plot

```{r}
unigrams_df %<>% anti_join(stop_words) 
```

```{r}
unigrams_df %>%
  group_by(question_word, word) %>% 
  count() %>% 
  top_n(5) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = question_word)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "count") +
  facet_wrap(~question_word, scales = "free") +
  coord_flip()
```

## Bigram analyses

What are the most common words that appear with the canonical question words?

```{r}
bigrams_df <- all_qs %>% 
  mutate(word = gloss) %>% 
  anti_join(custom_stop_words) %>% 
  distinct(sentgloss, .keep_all = T) %>% 
  unnest_tokens(bigram, sentgloss, token = "ngrams", n = 2) %>% 
  select(-gloss)
```

```{r}
bigram_plot <- bigrams_df %>%
  group_by(bigram) %>% 
  count() %>% 
  top_n(10) %>% 
  arrange(desc(n)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram))))

bigram_plot %>% 
  ungroup %>%
  ggplot(aes(bigram, n)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "count") +
  coord_flip()
```

Plot relationship between adult and kid bigrams

```{r}
bigrams_cor_plot <- bigrams_df %>%
  group_by(speaker_clean) %>% 
  count(bigram) %>% 
  top_n(100) %>% 
  mutate(n = log(n)) %>% 
  spread(key = speaker_clean, value = n)

bigrams_cor_plot %>% 
  filter(complete.cases(.)) %>% 
  ggplot(aes(x = child, y = adult)) +
  geom_point(alpha = 0.3) +
  geom_text(aes(label = bigram), check_overlap = TRUE) +
  geom_abline(slope=1, intercept=0, lty = 2) +
  lims(x = c(2,9), y = c(2,9))
```

## Most frequent bigrams for each child

```{r}
bigrams_child <- bigrams_df %>% 
  filter(speaker_clean == "child") %>% 
  mutate(bigram = str_replace_all(bigram, pattern = "0", replacement = "")) %>% # get rid of 0
  count(bigram, child_clean) %>% 
  group_by(child_clean) %>%
  mutate(proportion = n / sum(n))
```

```{r}
bigrams_child %>% 
  filter(n > 5) %>% 
  top_n(1) %>% 
  ungroup %>% 
  mutate(bigram = reorder(bigram, proportion)) %>%
  ggplot(aes(bigram, proportion, fill = child_clean)) +
  geom_col() +
  labs(x = NULL, y = "proportion of bigrams") +
  coord_flip() 
```


Now do the same thing, but for each question word type

```{r}
bigrams_df %>% 
  group_by(question_word) %>% 
  count(bigram, sort = T) %>% 
  mutate(proportion = n / sum(n)) %>% 
  top_n(5) %>% 
  arrange(desc(proportion)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  ggplot(., aes(x = bigram, y = proportion, fill = question_word)) +
  geom_col(show.legend = F) +
  labs(x = NULL, y = "proportion of bigrams") +
  coord_flip() +
  facet_wrap(~question_word, scales = "free")
```

### Trigrams

```{r}
trigrams_df <- all_qs %>% 
  distinct(sentgloss, .keep_all = T) %>% 
  unnest_tokens(trigram, sentgloss, token = "ngrams", n = 3)
```

```{r}
trigram_plot <- trigrams_df %>%
  group_by(trigram) %>% 
  count() %>% 
  top_n(15) %>% 
  arrange(desc(n)) %>%
  mutate(trigram = factor(trigram, levels = rev(unique(trigram))))

trigram_plot %>% 
  ungroup %>%
  ggplot(aes(trigram, n)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "count") +
  coord_flip()
```

Plot trigrams by question word type for adult questions

```{r}
trigrams_prop_plot <- trigrams_df %>% 
  filter(speaker_clean != "child") %>% 
  group_by(question_word) %>% 
  count(trigram, sort = T) %>% 
  mutate(proportion = n / sum(n)) %>% 
  top_n(5) %>% 
  arrange(desc(proportion)) %>%
  mutate(trigram = factor(trigram, levels = rev(unique(trigram)))) %>% 
  ggplot(., aes(x = trigram, y = proportion, fill = question_word)) +
  geom_col(show.legend = F) +
  labs(x = NULL, y = "proportion of trigrams") +
  labs(title = "Most frequent trigrams in adult questions by question type") +
  coord_flip() +
  facet_wrap(~question_word, scales = "free") +
  theme_bw()
```

What about splitting the most frequent trigrams by kid? 

```{r}
trigrams_by_kid <- trigrams_df %>%
  filter(speaker_clean != "child") %>% 
  group_by(child_clean) %>% 
  count(trigram) %>% 
  top_n(5) %>% 
  arrange(desc(n)) %>%
  mutate(trigram = factor(trigram, levels = rev(unique(trigram))))

trigrams_by_kid %>% 
  filter(n >= 10) %>% 
  ungroup %>%
  ggplot(aes(trigram, n, fill = child_clean)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "count") +
  coord_flip() +
  facet_wrap(~child_clean, scales = "free")
```

